# PPE Detector for Employee Safety

![PPE Detector for Employee Safety output example](sample_data/demo_output_images/image2.jpg?raw=true)
_Photo by Susan A. Romano_

[The PPE Detector for Employee Safety](https://aws.amazon.com/marketplace/pp/prodview-b53upp27dnmzq) - is a real-time computer vision model for identifying PPE non-compliance in working environments. The solution is a tool to ensure worker safety on building sites, fabrication lines, laboratories, steel, oil & gas enterprises, and other industrial environments where safety rules should be strictly followed. The solution is trained on the dataset manually selected and annotated by the VITechLab team. It detects if any of the following objects are missing: Coat, Glasses, Glove, Mask, Helmet. It works with live streams from CCTV cameras. This AI-based pre-packed solution is available for a subscription now.

### Are you looking to kick off an ML-driven worker safety initiative at your enterprise? [Contact us](https://vitechlab.com/) for details â€” we're now looking for pilot project teams to test the solution and will be happy to cooperate.

## Usage Information

Using our model for real time prediction is as simple as this:

```python
predictor = sagemaker.predictor.RealTimePredictor(
    ' your endpoint name ',
    sagemaker_session=sagemaker.Session(),
    content_type="image/jpeg"
)

with open('data/sample_image.jpg', 'rb') as img:
    img_bytes = bytearray(img.read())
    result = predictor.predict(img_bytes).decode("utf-8")
```

Also we've published two notebooks showing how to use our model:
* [Using-Personal-Protection-Equipment-Detector-Endpoint.ipynb](Using-Personal-Protection-Equipment-Detector-Endpoint.ipynb) notebook shows how you can use Python API to perform inference on endpoint created from the model
* [Using-Personal-Protection-Equipment-Detection-model.ipynb](Using-Personal-Protection-Equipment-Detection-model.ipynb) notebook shows how you can use Python API to run the full scenario:
    * deploy our model to create an endpoint
    * run Real Time inference on endpoint using local image
    * visualize  and save the prediction on original image
    * run Batch Transform job to perfom the inference on your data stored in Amazon S3 bucket

## Input\output data examples

* You can find sample input data in [demo_input](sample_data/demo_input) folder
* [demo_output_images](sample_data/demo_output_images) folder contains images with detections predicted by the model and visualized using `utils.visualize_detection` method
* [demo_raw_output](sample_data/demo_raw_output) folder contains raw output generated by our model using `Batch Transform` approach

## Sample detection results:

![PPE Detector for Employee Safety output example](sample_data/demo_output_images/image1.jpg?raw=true)

![PPE Detector for Employee Safety output example](sample_data/demo_output_images/image3.jpg?raw=true)

![PPE Detector for Employee Safety output example](sample_data/demo_output_images/image4.jpg?raw=true)

![PPE Detector for Employee Safety output example](sample_data/demo_output_images/image5.jpg?raw=true)

![PPE Detector for Employee Safety output example](sample_data/demo_output_images/image7.jpg?raw=true)
